{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.8.1 64-bit",
      "language": "python",
      "name": "python38164bit9c5a7ae0ec6d4dd18fad97f814710e5e"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.1-final"
    },
    "colab": {
      "name": "StarterNotebook_Updated.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZISOJvK2r-J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np \n",
        "from tqdm import tqdm\n",
        "import math\n",
        "import gc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-Ax1sD7qpB3",
        "colab_type": "text"
      },
      "source": [
        "**Locate Data in your Google Drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6O6Kfn2UtGgp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0c086505-335c-4d5d-eb48-a2438fc74066"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32DaUycu2r-P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataLocation = \"/content/drive/My Drive/COS 711/Assignments/Assignment 3/data/\"\n",
        "\n",
        "train=pd.read_csv(dataLocation + \"Train.csv\")\n",
        "test=pd.read_csv(dataLocation + \"Test.csv\")\n",
        "sample_sub=pd.read_csv(dataLocation + \"sample_sub.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbaVbxOqqcOR",
        "colab_type": "text"
      },
      "source": [
        "# Inspect Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAGKyM9d2r-U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "9532f08a-ff2b-463a-d596-98cbc871a1cb"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>location</th>\n",
              "      <th>temp</th>\n",
              "      <th>precip</th>\n",
              "      <th>rel_humidity</th>\n",
              "      <th>wind_dir</th>\n",
              "      <th>wind_spd</th>\n",
              "      <th>atmos_press</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ID_train_0</td>\n",
              "      <td>C</td>\n",
              "      <td>nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,na...</td>\n",
              "      <td>nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,na...</td>\n",
              "      <td>nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,na...</td>\n",
              "      <td>nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,na...</td>\n",
              "      <td>nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,na...</td>\n",
              "      <td>nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,na...</td>\n",
              "      <td>45.126304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ID_train_1</td>\n",
              "      <td>D</td>\n",
              "      <td>22.53333333,21.71666667,20.83333333,20.9833333...</td>\n",
              "      <td>0.102,0.0,0.0,0.0,0.0,0.0,0.0,0.034,0.017,0.01...</td>\n",
              "      <td>0.744583333,0.808083333,0.911166667,0.91633333...</td>\n",
              "      <td>281.6643101,89.15629262,81.96853891,291.018632...</td>\n",
              "      <td>2.3775,1.126666667,0.700833333,0.3416666670000...</td>\n",
              "      <td>90.32,90.3775,90.44083333,90.4725,90.45416667,...</td>\n",
              "      <td>79.131702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ID_train_10</td>\n",
              "      <td>A</td>\n",
              "      <td>28.975,27.95,29.6,26.425,22.09166667,21.775,22...</td>\n",
              "      <td>0.0,0.0,0.0,0.102,0.136,0.0,0.0,2.16,1.276,0.0...</td>\n",
              "      <td>0.573333333,0.597166667,0.5668333329999999,0.6...</td>\n",
              "      <td>nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,na...</td>\n",
              "      <td>nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,na...</td>\n",
              "      <td>88.55166667,88.46416667,88.31916667,88.24,88.2...</td>\n",
              "      <td>32.661304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ID_train_100</td>\n",
              "      <td>A</td>\n",
              "      <td>22.96666667,24.26666667,25.275,25.625,25.86666...</td>\n",
              "      <td>0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,7.77,3.012,1.0...</td>\n",
              "      <td>0.8430833329999999,0.79025,0.7375,0.728,0.7049...</td>\n",
              "      <td>300.0850574,293.6769595,294.5174647,301.921416...</td>\n",
              "      <td>1.446666667,1.1925,1.324166667,1.5441666669999...</td>\n",
              "      <td>88.615,88.53083333,88.4,88.27166667,88.2075,88...</td>\n",
              "      <td>53.850238</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ID_train_1000</td>\n",
              "      <td>A</td>\n",
              "      <td>21.875,21.575,21.525,21.43333333,20.50833333,1...</td>\n",
              "      <td>0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0....</td>\n",
              "      <td>0.8564166670000001,0.874916667,0.879833333,0.8...</td>\n",
              "      <td>21.83997432,17.05405341,89.26406044,123.585424...</td>\n",
              "      <td>0.1975,0.244166667,0.411666667,0.56,0.5775,0.4...</td>\n",
              "      <td>88.55666667,88.64083333,88.65833333,88.6475,88...</td>\n",
              "      <td>177.418750</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              ID  ...      target\n",
              "0     ID_train_0  ...   45.126304\n",
              "1     ID_train_1  ...   79.131702\n",
              "2    ID_train_10  ...   32.661304\n",
              "3   ID_train_100  ...   53.850238\n",
              "4  ID_train_1000  ...  177.418750\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54HSVXH32r-Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "6475769d-a788-4725-f0ec-74a19ed976e0"
      },
      "source": [
        "test.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>location</th>\n",
              "      <th>temp</th>\n",
              "      <th>precip</th>\n",
              "      <th>rel_humidity</th>\n",
              "      <th>wind_dir</th>\n",
              "      <th>wind_spd</th>\n",
              "      <th>atmos_press</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ID_test_0</td>\n",
              "      <td>C</td>\n",
              "      <td>23.96666667,22.88333333,22.28333333,21.4833333...</td>\n",
              "      <td>0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0....</td>\n",
              "      <td>0.6898333329999999,0.722333333,0.7755833329999...</td>\n",
              "      <td>290.1352379,328.47011289999995,323.5730796,282...</td>\n",
              "      <td>0.6333333329999999,0.725,0.955,0.8725,0.6925,0...</td>\n",
              "      <td>87.64333333,87.67,87.70583333,87.75083333,87.7...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ID_test_1</td>\n",
              "      <td>C</td>\n",
              "      <td>18.99166667,19.70833333,20.95833333,22.7833333...</td>\n",
              "      <td>0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0....</td>\n",
              "      <td>0.99975,0.99725,0.956333333,0.851583333,0.7775...</td>\n",
              "      <td>295.2350543,307.6569135,313.7360236,311.518385...</td>\n",
              "      <td>0.640833333,1.244166667,1.284166667,1.2875,1.3...</td>\n",
              "      <td>87.8925,87.95666667,87.9925,87.9925,87.9808333...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ID_test_10</td>\n",
              "      <td>D</td>\n",
              "      <td>25.11666667,25.08333333,24.40833333,23.575,22....</td>\n",
              "      <td>0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0....</td>\n",
              "      <td>0.760166667,0.733583333,0.78475,0.825833333,0....</td>\n",
              "      <td>77.06161145,95.48124997,61.44498258,89.4688360...</td>\n",
              "      <td>2.0133333330000003,1.3025,0.783333333,0.530833...</td>\n",
              "      <td>90.34,90.2975,90.305,90.35583333,90.4425,90.49...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ID_test_100</td>\n",
              "      <td>C</td>\n",
              "      <td>18.71666667,20.60833333,22.28333333,23.9833333...</td>\n",
              "      <td>0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,3.604,0.0,0.0,...</td>\n",
              "      <td>0.951416667,0.92575,0.8603333329999999,0.77883...</td>\n",
              "      <td>310.7509058,316.186793,324.8167326,327.2174992...</td>\n",
              "      <td>0.745,1.169166667,1.316666667,1.385,1.40083333...</td>\n",
              "      <td>87.98833333,88.06333333,88.07833333,88.0366666...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ID_test_1000</td>\n",
              "      <td>D</td>\n",
              "      <td>17.63333333,18.05833333,19.625,21.28333333,23....</td>\n",
              "      <td>0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0....</td>\n",
              "      <td>0.9,0.898333333,0.8725,0.831666667,0.820833332...</td>\n",
              "      <td>334.6054069,329.6848561000001,322.7668036,312....</td>\n",
              "      <td>0.620833333,0.5,0.456666667,0.558333333,1.0158...</td>\n",
              "      <td>90.515,90.5575,90.62333333,90.6825,90.67916667...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             ID  ...                                        atmos_press\n",
              "0     ID_test_0  ...  87.64333333,87.67,87.70583333,87.75083333,87.7...\n",
              "1     ID_test_1  ...  87.8925,87.95666667,87.9925,87.9925,87.9808333...\n",
              "2    ID_test_10  ...  90.34,90.2975,90.305,90.35583333,90.4425,90.49...\n",
              "3   ID_test_100  ...  87.98833333,88.06333333,88.07833333,88.0366666...\n",
              "4  ID_test_1000  ...  90.515,90.5575,90.62333333,90.6825,90.67916667...\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZULF2qPqjIn",
        "colab_type": "text"
      },
      "source": [
        "## Handle Missing Data\n",
        "We replace the missing values with -100."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAsMnJrRrDXP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def parseTimeSeriesData(timeSeries):\n",
        "    timeSeries = timeSeries.replace(\"nan\",\"-100\").split(\",\")\n",
        "    parsedTimeSeries = np.array([float(timeSeries) for timeSeries in timeSeries])\n",
        "    return parsedTimeSeries\n",
        "\n",
        "def extractTimeSeries(pattern, featureName):\n",
        "    return np.array(pattern[featureName].apply(lambda timeSeries: parseTimeSeriesData(timeSeries)).tolist())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0OUPEJOo7T0",
        "colab_type": "text"
      },
      "source": [
        "## Transpose the data.\n",
        "(121, 6) -> (6, 121)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-Yigv8mrEaf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "featureNames = ['temp', 'precip', 'rel_humidity', 'wind_dir', 'wind_spd', 'atmos_press']\n",
        "\n",
        "trainData = np.array([extractTimeSeries(train, featureName) for featureName in featureNames]).transpose(1,2,0)\n",
        "testData = np.array([extractTimeSeries(test, featureName) for featureName in featureNames]).transpose(1,2,0)\n",
        "trainTargets = train['target'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZu695gMutDl",
        "colab_type": "text"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyNrZHnko1iM",
        "colab_type": "text"
      },
      "source": [
        "## Encode the location of the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTpi6phpvOJe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encodeLocation(pattern):\n",
        "    encoding = {\n",
        "        'A':0,\n",
        "        'B':1,\n",
        "        'C':2,\n",
        "        'D':3,\n",
        "        'E':4\n",
        "    }\n",
        "    return pattern['location'].apply(lambda encoding:pattern[encoding])\n",
        "\n",
        "trainLocations = encodeLocation(train).values\n",
        "testLocations = encodeLocation(test).values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUsBMvWQozMO",
        "colab_type": "text"
      },
      "source": [
        "## Normalise Data\n",
        "Using Z score normalisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_v_FR2Nuxtb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "allFeatures = np.concatenate([trainData, testData], axis = 0)\n",
        "\n",
        "for item in range(allFeatures.shape[2]):\n",
        "    validIndex = np.where(allFeatures[:,:,c] != -100)\n",
        "    mean = allFeatures[:,:,item][validIndex].mean()\n",
        "    std = allFeatures[:,:,item][validIndex].std()\n",
        "    \n",
        "    allFeatures[:,:,item][validIndex] -= mean\n",
        "    allFeatures[:,:,item][validIndex] /= std\n",
        "\n",
        "trainData = allFeatures[:trainLocations.shape[0]]\n",
        "testData = allFeatures[trainLocations.shape[0]:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBPxMWQXX3Cc",
        "colab_type": "text"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydeUxXQQX5iD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataSet():\n",
        "    def __init__(self, patterns, target, indices=None, split='a'):\n",
        "        if indices is None:\n",
        "            self.patterns = patterns\n",
        "            self.target = target\n",
        "        else:\n",
        "            self.patterns = patterns[indices]\n",
        "            self.target = target[indices]\n",
        "        \n",
        "        self.split = split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RHlt9T29djm",
        "colab_type": "text"
      },
      "source": [
        "## Logic"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JwlEOkSAJQI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow import keras\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from numpy import mean, std, min\n",
        "\n",
        "foldsSplits = 10\n",
        "epochs = 15"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBTLeDocyoBF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculatePerformance(history):\n",
        "    validationLosses = history.history['val_loss']\n",
        "    return min(validationLosses)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqUYPP6r9NJe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def trainModel(model: keras.models.Sequential, trainData: DataSet, valData: DataSet, epochs):\n",
        "    history = model.fit(\n",
        "        x=trainData.patterns,\n",
        "        y=trainData.target,\n",
        "        validation_data=(valData.patterns, valData.target),\n",
        "        epochs=epochs,\n",
        "        verbose=2,\n",
        "    )\n",
        "    score = calculatePerformance(history)\n",
        "    return model, score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5uAQ2vpXIo8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def testAlgorithm(modelCreation):\n",
        "    global foldsSplits\n",
        "    global epochs\n",
        "    kFold = StratifiedKFold(n_splits=foldsSplits, random_state=2020, shuffle=True)\n",
        "\n",
        "    scores = []\n",
        "    fold = 0\n",
        "    for trainIndex, valIndex in kFold.split(trainData, trainLocations):\n",
        "        print('Training fold:', fold)\n",
        "        fold += 1\n",
        "        dataSets = {'train': DataSet(trainData, trainTargets, trainIndex, split = 'train'),\n",
        "              'validation': DataSet(trainData, trainTargets, valIndex, split = 'validation'),\n",
        "              'test': DataSet(testData, None, split = 'validation')}\n",
        "\n",
        "        inputSize = len(trainData[0][0])\n",
        "        model = modelCreation(inputSize)\n",
        "        model, score = trainModel(model, dataSets['train'], dataSets['validation'], epochs)\n",
        "        print(\"Fold Score: \", score)\n",
        "        scores.append(score)\n",
        "    return scores\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqN6RV9P_5Fe",
        "colab_type": "text"
      },
      "source": [
        "# Convolutional NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqYGq1o8ABAp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def createCNNModel(inputSize):\n",
        "\n",
        "    kernelSize = inputSize + 2\n",
        "\n",
        "    model: keras.models.Sequential = keras.models.Sequential()\n",
        "    model.add(keras.layers.Conv1D(inputSize, kernelSize, activation=keras.activations.relu))\n",
        "    model.add(keras.layers.MaxPool1D())\n",
        "    model.add(keras.layers.Conv1D(32, kernelSize, activation=keras.activations.relu))\n",
        "    model.add(keras.layers.MaxPool1D())\n",
        "    model.add(keras.layers.Conv1D(64, kernelSize, activation=keras.activations.relu))\n",
        "    model.add(keras.layers.Dense(64, keras.activations.relu))\n",
        "    model.add(keras.layers.Dense(1, keras.activations.relu))\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "        loss='mse',\n",
        "        metrics=['mse'])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHOKFfMs0tLT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e01a1e81-3964-4b03-ff1e-36d3875999e2"
      },
      "source": [
        "cnnScores = testAlgorithm(createCNNModel)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training fold: 0\n",
            "Epoch 1/15\n",
            "438/438 - 4s - loss: 2181.9961 - mse: 2181.9961 - val_loss: 1469.6099 - val_mse: 1469.6099\n",
            "Epoch 2/15\n",
            "438/438 - 4s - loss: 1634.4282 - mse: 1634.4282 - val_loss: 1381.9690 - val_mse: 1381.9690\n",
            "Epoch 3/15\n",
            "438/438 - 4s - loss: 1603.2919 - mse: 1603.2919 - val_loss: 1388.5226 - val_mse: 1388.5226\n",
            "Epoch 4/15\n",
            "438/438 - 4s - loss: 1588.0895 - mse: 1588.0895 - val_loss: 1335.8751 - val_mse: 1335.8751\n",
            "Epoch 5/15\n",
            "438/438 - 4s - loss: 1591.1191 - mse: 1591.1191 - val_loss: 1344.2921 - val_mse: 1344.2921\n",
            "Epoch 6/15\n",
            "438/438 - 4s - loss: 1552.3832 - mse: 1552.3832 - val_loss: 1404.8209 - val_mse: 1404.8209\n",
            "Epoch 7/15\n",
            "438/438 - 4s - loss: 1540.3865 - mse: 1540.3865 - val_loss: 1324.7272 - val_mse: 1324.7272\n",
            "Epoch 8/15\n",
            "438/438 - 4s - loss: 1531.8767 - mse: 1531.8767 - val_loss: 1316.0332 - val_mse: 1316.0332\n",
            "Epoch 9/15\n",
            "438/438 - 4s - loss: 1518.2869 - mse: 1518.2869 - val_loss: 1324.1537 - val_mse: 1324.1537\n",
            "Epoch 10/15\n",
            "438/438 - 4s - loss: 1505.7505 - mse: 1505.7505 - val_loss: 1378.7395 - val_mse: 1378.7395\n",
            "Epoch 11/15\n",
            "438/438 - 4s - loss: 1509.9816 - mse: 1509.9816 - val_loss: 1317.8442 - val_mse: 1317.8442\n",
            "Epoch 12/15\n",
            "438/438 - 4s - loss: 1502.6821 - mse: 1502.6821 - val_loss: 1292.8950 - val_mse: 1292.8950\n",
            "Epoch 13/15\n",
            "438/438 - 4s - loss: 1496.6947 - mse: 1496.6947 - val_loss: 1336.1870 - val_mse: 1336.1870\n",
            "Epoch 14/15\n",
            "438/438 - 4s - loss: 1497.3457 - mse: 1497.3457 - val_loss: 1293.4958 - val_mse: 1293.4958\n",
            "Epoch 15/15\n",
            "438/438 - 4s - loss: 1483.7582 - mse: 1483.7582 - val_loss: 1371.4535 - val_mse: 1371.4535\n",
            "Fold Score:  1292.89501953125\n",
            "Training fold: 1\n",
            "Epoch 1/15\n",
            "438/438 - 4s - loss: 2113.0999 - mse: 2113.0999 - val_loss: 1656.4399 - val_mse: 1656.4399\n",
            "Epoch 2/15\n",
            "438/438 - 4s - loss: 1626.6555 - mse: 1626.6555 - val_loss: 1587.0477 - val_mse: 1587.0477\n",
            "Epoch 3/15\n",
            "438/438 - 4s - loss: 1581.1063 - mse: 1581.1063 - val_loss: 1578.3789 - val_mse: 1578.3789\n",
            "Epoch 4/15\n",
            "438/438 - 4s - loss: 1560.8988 - mse: 1560.8988 - val_loss: 1559.7727 - val_mse: 1559.7727\n",
            "Epoch 5/15\n",
            "438/438 - 4s - loss: 1550.6179 - mse: 1550.6179 - val_loss: 1596.5365 - val_mse: 1596.5365\n",
            "Epoch 6/15\n",
            "438/438 - 4s - loss: 1541.0116 - mse: 1541.0116 - val_loss: 1528.4255 - val_mse: 1528.4255\n",
            "Epoch 7/15\n",
            "438/438 - 4s - loss: 1519.0936 - mse: 1519.0936 - val_loss: 1545.5892 - val_mse: 1545.5892\n",
            "Epoch 8/15\n",
            "438/438 - 4s - loss: 1520.7068 - mse: 1520.7068 - val_loss: 1511.7539 - val_mse: 1511.7539\n",
            "Epoch 9/15\n",
            "438/438 - 4s - loss: 1514.8948 - mse: 1514.8948 - val_loss: 1511.4030 - val_mse: 1511.4030\n",
            "Epoch 10/15\n",
            "438/438 - 4s - loss: 1504.0662 - mse: 1504.0662 - val_loss: 1552.1174 - val_mse: 1552.1174\n",
            "Epoch 11/15\n",
            "438/438 - 4s - loss: 1491.3638 - mse: 1491.3638 - val_loss: 1500.6376 - val_mse: 1500.6376\n",
            "Epoch 12/15\n",
            "438/438 - 4s - loss: 1497.4098 - mse: 1497.4098 - val_loss: 1517.1414 - val_mse: 1517.1414\n",
            "Epoch 13/15\n",
            "438/438 - 4s - loss: 1484.2126 - mse: 1484.2126 - val_loss: 1497.1962 - val_mse: 1497.1962\n",
            "Epoch 14/15\n",
            "438/438 - 4s - loss: 1474.0231 - mse: 1474.0231 - val_loss: 1535.7803 - val_mse: 1535.7803\n",
            "Epoch 15/15\n",
            "438/438 - 4s - loss: 1467.7612 - mse: 1467.7612 - val_loss: 1533.8663 - val_mse: 1533.8663\n",
            "Fold Score:  1497.1961669921875\n",
            "Training fold: 2\n",
            "Epoch 1/15\n",
            "438/438 - 4s - loss: 2057.9768 - mse: 2057.9768 - val_loss: 1686.9020 - val_mse: 1686.9020\n",
            "Epoch 2/15\n",
            "438/438 - 4s - loss: 1574.1056 - mse: 1574.1056 - val_loss: 1648.1493 - val_mse: 1648.1493\n",
            "Epoch 3/15\n",
            "438/438 - 4s - loss: 1546.6592 - mse: 1546.6592 - val_loss: 1605.7352 - val_mse: 1605.7352\n",
            "Epoch 4/15\n",
            "438/438 - 4s - loss: 1545.6460 - mse: 1545.6460 - val_loss: 1596.2631 - val_mse: 1596.2631\n",
            "Epoch 5/15\n",
            "438/438 - 4s - loss: 1514.9227 - mse: 1514.9227 - val_loss: 1623.6553 - val_mse: 1623.6553\n",
            "Epoch 6/15\n",
            "438/438 - 4s - loss: 1515.5701 - mse: 1515.5701 - val_loss: 1593.5098 - val_mse: 1593.5098\n",
            "Epoch 7/15\n",
            "438/438 - 4s - loss: 1510.0494 - mse: 1510.0494 - val_loss: 1580.3961 - val_mse: 1580.3961\n",
            "Epoch 8/15\n",
            "438/438 - 4s - loss: 1506.7458 - mse: 1506.7458 - val_loss: 1606.4392 - val_mse: 1606.4392\n",
            "Epoch 9/15\n",
            "438/438 - 3s - loss: 1484.8448 - mse: 1484.8448 - val_loss: 1540.5795 - val_mse: 1540.5795\n",
            "Epoch 10/15\n",
            "438/438 - 4s - loss: 1487.5807 - mse: 1487.5807 - val_loss: 1527.8815 - val_mse: 1527.8815\n",
            "Epoch 11/15\n",
            "438/438 - 3s - loss: 1481.7396 - mse: 1481.7396 - val_loss: 1548.8300 - val_mse: 1548.8300\n",
            "Epoch 12/15\n",
            "438/438 - 4s - loss: 1479.4723 - mse: 1479.4723 - val_loss: 1522.0110 - val_mse: 1522.0110\n",
            "Epoch 13/15\n",
            "438/438 - 4s - loss: 1467.5704 - mse: 1467.5704 - val_loss: 1512.5668 - val_mse: 1512.5668\n",
            "Epoch 14/15\n",
            "438/438 - 3s - loss: 1467.7921 - mse: 1467.7921 - val_loss: 1507.6710 - val_mse: 1507.6710\n",
            "Epoch 15/15\n",
            "438/438 - 3s - loss: 1465.4061 - mse: 1465.4061 - val_loss: 1538.6730 - val_mse: 1538.6730\n",
            "Fold Score:  1507.6710205078125\n",
            "Training fold: 3\n",
            "Epoch 1/15\n",
            "438/438 - 4s - loss: 2140.8401 - mse: 2140.8401 - val_loss: 1471.9326 - val_mse: 1471.9326\n",
            "Epoch 2/15\n",
            "438/438 - 4s - loss: 1618.2281 - mse: 1618.2281 - val_loss: 1406.7878 - val_mse: 1406.7878\n",
            "Epoch 3/15\n",
            "438/438 - 4s - loss: 1620.1509 - mse: 1620.1509 - val_loss: 1445.0713 - val_mse: 1445.0713\n",
            "Epoch 4/15\n",
            "438/438 - 4s - loss: 1578.4465 - mse: 1578.4465 - val_loss: 1417.3765 - val_mse: 1417.3765\n",
            "Epoch 5/15\n",
            "438/438 - 4s - loss: 1561.3182 - mse: 1561.3182 - val_loss: 1487.9867 - val_mse: 1487.9867\n",
            "Epoch 6/15\n",
            "438/438 - 4s - loss: 1565.7356 - mse: 1565.7356 - val_loss: 1384.5591 - val_mse: 1384.5591\n",
            "Epoch 7/15\n",
            "438/438 - 4s - loss: 1550.9352 - mse: 1550.9352 - val_loss: 1374.6572 - val_mse: 1374.6572\n",
            "Epoch 8/15\n",
            "438/438 - 4s - loss: 1538.6853 - mse: 1538.6853 - val_loss: 1362.0107 - val_mse: 1362.0107\n",
            "Epoch 9/15\n",
            "438/438 - 4s - loss: 1534.8823 - mse: 1534.8823 - val_loss: 1396.3411 - val_mse: 1396.3411\n",
            "Epoch 10/15\n",
            "438/438 - 4s - loss: 1525.5155 - mse: 1525.5155 - val_loss: 1384.7242 - val_mse: 1384.7242\n",
            "Epoch 11/15\n",
            "438/438 - 4s - loss: 1516.8951 - mse: 1516.8951 - val_loss: 1371.3987 - val_mse: 1371.3987\n",
            "Epoch 12/15\n",
            "438/438 - 4s - loss: 1505.8538 - mse: 1505.8538 - val_loss: 1348.1155 - val_mse: 1348.1155\n",
            "Epoch 13/15\n",
            "438/438 - 4s - loss: 1503.4788 - mse: 1503.4788 - val_loss: 1480.1715 - val_mse: 1480.1715\n",
            "Epoch 14/15\n",
            "438/438 - 4s - loss: 1490.5826 - mse: 1490.5826 - val_loss: 1326.6598 - val_mse: 1326.6598\n",
            "Epoch 15/15\n",
            "438/438 - 4s - loss: 1501.0430 - mse: 1501.0430 - val_loss: 1343.2020 - val_mse: 1343.2020\n",
            "Fold Score:  1326.6597900390625\n",
            "Training fold: 4\n",
            "Epoch 1/15\n",
            "438/438 - 4s - loss: 2163.2991 - mse: 2163.2991 - val_loss: 1648.6938 - val_mse: 1648.6938\n",
            "Epoch 2/15\n",
            "438/438 - 4s - loss: 1643.3060 - mse: 1643.3060 - val_loss: 1601.4391 - val_mse: 1601.4391\n",
            "Epoch 3/15\n",
            "438/438 - 4s - loss: 1599.6729 - mse: 1599.6729 - val_loss: 1552.9399 - val_mse: 1552.9399\n",
            "Epoch 4/15\n",
            "438/438 - 4s - loss: 1591.9144 - mse: 1591.9144 - val_loss: 1632.2150 - val_mse: 1632.2150\n",
            "Epoch 5/15\n",
            "438/438 - 4s - loss: 1565.9581 - mse: 1565.9581 - val_loss: 1594.5905 - val_mse: 1594.5905\n",
            "Epoch 6/15\n",
            "438/438 - 4s - loss: 1555.5226 - mse: 1555.5226 - val_loss: 1651.2100 - val_mse: 1651.2100\n",
            "Epoch 7/15\n",
            "438/438 - 4s - loss: 1565.9663 - mse: 1565.9663 - val_loss: 1637.1802 - val_mse: 1637.1802\n",
            "Epoch 8/15\n",
            "438/438 - 4s - loss: 1553.8083 - mse: 1553.8083 - val_loss: 1530.0886 - val_mse: 1530.0886\n",
            "Epoch 9/15\n",
            "438/438 - 4s - loss: 1527.9103 - mse: 1527.9103 - val_loss: 1528.2950 - val_mse: 1528.2950\n",
            "Epoch 10/15\n",
            "438/438 - 4s - loss: 1521.6626 - mse: 1521.6626 - val_loss: 1512.1934 - val_mse: 1512.1934\n",
            "Epoch 11/15\n",
            "438/438 - 4s - loss: 1506.6997 - mse: 1506.6997 - val_loss: 1550.1473 - val_mse: 1550.1473\n",
            "Epoch 12/15\n",
            "438/438 - 4s - loss: 1501.9565 - mse: 1501.9565 - val_loss: 1473.5121 - val_mse: 1473.5121\n",
            "Epoch 13/15\n",
            "438/438 - 4s - loss: 1503.9998 - mse: 1503.9998 - val_loss: 1469.4033 - val_mse: 1469.4033\n",
            "Epoch 14/15\n",
            "438/438 - 4s - loss: 1505.0299 - mse: 1505.0299 - val_loss: 1463.3539 - val_mse: 1463.3539\n",
            "Epoch 15/15\n",
            "438/438 - 4s - loss: 1492.1415 - mse: 1492.1415 - val_loss: 1500.7617 - val_mse: 1500.7617\n",
            "Fold Score:  1463.3538818359375\n",
            "Training fold: 5\n",
            "Epoch 1/15\n",
            "438/438 - 4s - loss: 2049.2219 - mse: 2049.2219 - val_loss: 1872.3994 - val_mse: 1872.3994\n",
            "Epoch 2/15\n",
            "438/438 - 4s - loss: 1579.6045 - mse: 1579.6045 - val_loss: 1782.9515 - val_mse: 1782.9515\n",
            "Epoch 3/15\n",
            "438/438 - 4s - loss: 1540.2626 - mse: 1540.2626 - val_loss: 1773.7615 - val_mse: 1773.7615\n",
            "Epoch 4/15\n",
            "438/438 - 4s - loss: 1526.2616 - mse: 1526.2616 - val_loss: 1763.4128 - val_mse: 1763.4128\n",
            "Epoch 5/15\n",
            "438/438 - 4s - loss: 1515.3258 - mse: 1515.3258 - val_loss: 1724.0532 - val_mse: 1724.0532\n",
            "Epoch 6/15\n",
            "438/438 - 4s - loss: 1501.5706 - mse: 1501.5706 - val_loss: 1756.7947 - val_mse: 1756.7947\n",
            "Epoch 7/15\n",
            "438/438 - 4s - loss: 1496.6520 - mse: 1496.6520 - val_loss: 1788.1271 - val_mse: 1788.1271\n",
            "Epoch 8/15\n",
            "438/438 - 4s - loss: 1482.0057 - mse: 1482.0057 - val_loss: 1713.5475 - val_mse: 1713.5475\n",
            "Epoch 9/15\n",
            "438/438 - 4s - loss: 1475.7830 - mse: 1475.7830 - val_loss: 1708.8733 - val_mse: 1708.8733\n",
            "Epoch 10/15\n",
            "438/438 - 4s - loss: 1468.3048 - mse: 1468.3048 - val_loss: 1710.8770 - val_mse: 1710.8770\n",
            "Epoch 11/15\n",
            "438/438 - 4s - loss: 1459.0579 - mse: 1459.0579 - val_loss: 1690.4696 - val_mse: 1690.4696\n",
            "Epoch 12/15\n",
            "438/438 - 4s - loss: 1457.6499 - mse: 1457.6499 - val_loss: 1694.7378 - val_mse: 1694.7378\n",
            "Epoch 13/15\n",
            "438/438 - 4s - loss: 1452.5519 - mse: 1452.5519 - val_loss: 1709.2980 - val_mse: 1709.2980\n",
            "Epoch 14/15\n",
            "438/438 - 4s - loss: 1445.3550 - mse: 1445.3550 - val_loss: 1683.3922 - val_mse: 1683.3922\n",
            "Epoch 15/15\n",
            "438/438 - 4s - loss: 1440.2670 - mse: 1440.2670 - val_loss: 1693.8420 - val_mse: 1693.8420\n",
            "Fold Score:  1683.3922119140625\n",
            "Training fold: 6\n",
            "Epoch 1/15\n",
            "438/438 - 4s - loss: 2120.9536 - mse: 2120.9536 - val_loss: 1658.6918 - val_mse: 1658.6918\n",
            "Epoch 2/15\n",
            "438/438 - 4s - loss: 1580.5935 - mse: 1580.5935 - val_loss: 1652.9418 - val_mse: 1652.9418\n",
            "Epoch 3/15\n",
            "438/438 - 4s - loss: 1556.1068 - mse: 1556.1068 - val_loss: 1614.1158 - val_mse: 1614.1158\n",
            "Epoch 4/15\n",
            "438/438 - 4s - loss: 1542.5576 - mse: 1542.5576 - val_loss: 1605.7157 - val_mse: 1605.7157\n",
            "Epoch 5/15\n",
            "438/438 - 4s - loss: 1529.5293 - mse: 1529.5293 - val_loss: 1593.1675 - val_mse: 1593.1675\n",
            "Epoch 6/15\n",
            "438/438 - 4s - loss: 1515.1073 - mse: 1515.1073 - val_loss: 1615.8037 - val_mse: 1615.8037\n",
            "Epoch 7/15\n",
            "438/438 - 4s - loss: 1514.7397 - mse: 1514.7397 - val_loss: 1558.7274 - val_mse: 1558.7274\n",
            "Epoch 8/15\n",
            "438/438 - 4s - loss: 1507.8933 - mse: 1507.8933 - val_loss: 1620.3065 - val_mse: 1620.3065\n",
            "Epoch 9/15\n",
            "438/438 - 4s - loss: 1497.7239 - mse: 1497.7239 - val_loss: 1667.2252 - val_mse: 1667.2252\n",
            "Epoch 10/15\n",
            "438/438 - 4s - loss: 1501.2633 - mse: 1501.2633 - val_loss: 1569.9440 - val_mse: 1569.9440\n",
            "Epoch 11/15\n",
            "438/438 - 4s - loss: 1478.9038 - mse: 1478.9038 - val_loss: 1560.2571 - val_mse: 1560.2571\n",
            "Epoch 12/15\n",
            "438/438 - 4s - loss: 1470.1110 - mse: 1470.1110 - val_loss: 1552.8792 - val_mse: 1552.8792\n",
            "Epoch 13/15\n",
            "438/438 - 4s - loss: 1465.6967 - mse: 1465.6967 - val_loss: 1536.0358 - val_mse: 1536.0358\n",
            "Epoch 14/15\n",
            "438/438 - 4s - loss: 1464.8488 - mse: 1464.8488 - val_loss: 1528.6271 - val_mse: 1528.6271\n",
            "Epoch 15/15\n",
            "438/438 - 4s - loss: 1453.8394 - mse: 1453.8394 - val_loss: 1552.0060 - val_mse: 1552.0060\n",
            "Fold Score:  1528.6270751953125\n",
            "Training fold: 7\n",
            "Epoch 1/15\n",
            "438/438 - 4s - loss: 1998.0624 - mse: 1998.0624 - val_loss: 1539.1862 - val_mse: 1539.1862\n",
            "Epoch 2/15\n",
            "438/438 - 4s - loss: 1601.8499 - mse: 1601.8499 - val_loss: 1429.2339 - val_mse: 1429.2339\n",
            "Epoch 3/15\n",
            "438/438 - 4s - loss: 1575.0776 - mse: 1575.0776 - val_loss: 1447.0780 - val_mse: 1447.0780\n",
            "Epoch 4/15\n",
            "438/438 - 4s - loss: 1557.7330 - mse: 1557.7330 - val_loss: 1447.3169 - val_mse: 1447.3169\n",
            "Epoch 5/15\n",
            "438/438 - 4s - loss: 1542.8578 - mse: 1542.8578 - val_loss: 1431.8336 - val_mse: 1431.8336\n",
            "Epoch 6/15\n",
            "438/438 - 4s - loss: 1536.0457 - mse: 1536.0457 - val_loss: 1449.9242 - val_mse: 1449.9242\n",
            "Epoch 7/15\n",
            "438/438 - 4s - loss: 1541.9778 - mse: 1541.9778 - val_loss: 1374.4288 - val_mse: 1374.4288\n",
            "Epoch 8/15\n",
            "438/438 - 4s - loss: 1515.0872 - mse: 1515.0872 - val_loss: 1370.6997 - val_mse: 1370.6997\n",
            "Epoch 9/15\n",
            "438/438 - 4s - loss: 1507.3098 - mse: 1507.3098 - val_loss: 1362.8503 - val_mse: 1362.8503\n",
            "Epoch 10/15\n",
            "438/438 - 4s - loss: 1499.7506 - mse: 1499.7506 - val_loss: 1379.5747 - val_mse: 1379.5747\n",
            "Epoch 11/15\n",
            "438/438 - 4s - loss: 1491.4824 - mse: 1491.4824 - val_loss: 1362.1792 - val_mse: 1362.1792\n",
            "Epoch 12/15\n",
            "438/438 - 4s - loss: 1488.4492 - mse: 1488.4492 - val_loss: 1351.4899 - val_mse: 1351.4899\n",
            "Epoch 13/15\n",
            "438/438 - 4s - loss: 1486.3179 - mse: 1486.3179 - val_loss: 1358.1487 - val_mse: 1358.1487\n",
            "Epoch 14/15\n",
            "438/438 - 4s - loss: 1477.2999 - mse: 1477.2999 - val_loss: 1346.4575 - val_mse: 1346.4575\n",
            "Epoch 15/15\n",
            "438/438 - 4s - loss: 1479.6300 - mse: 1479.6300 - val_loss: 1330.4297 - val_mse: 1330.4297\n",
            "Fold Score:  1330.4296875\n",
            "Training fold: 8\n",
            "Epoch 1/15\n",
            "438/438 - 4s - loss: 2182.0012 - mse: 2182.0012 - val_loss: 1841.4786 - val_mse: 1841.4786\n",
            "Epoch 2/15\n",
            "438/438 - 4s - loss: 1575.4674 - mse: 1575.4674 - val_loss: 1775.1444 - val_mse: 1775.1444\n",
            "Epoch 3/15\n",
            "438/438 - 4s - loss: 1540.8934 - mse: 1540.8934 - val_loss: 1746.6515 - val_mse: 1746.6515\n",
            "Epoch 4/15\n",
            "438/438 - 4s - loss: 1530.1787 - mse: 1530.1787 - val_loss: 1730.5486 - val_mse: 1730.5486\n",
            "Epoch 5/15\n",
            "438/438 - 4s - loss: 1520.0087 - mse: 1520.0087 - val_loss: 1717.5243 - val_mse: 1717.5243\n",
            "Epoch 6/15\n",
            "438/438 - 4s - loss: 1510.7427 - mse: 1510.7427 - val_loss: 1702.2653 - val_mse: 1702.2653\n",
            "Epoch 7/15\n",
            "438/438 - 4s - loss: 1503.2150 - mse: 1503.2150 - val_loss: 1725.9725 - val_mse: 1725.9725\n",
            "Epoch 8/15\n",
            "438/438 - 4s - loss: 1488.2582 - mse: 1488.2582 - val_loss: 1674.0173 - val_mse: 1674.0173\n",
            "Epoch 9/15\n",
            "438/438 - 4s - loss: 1490.2611 - mse: 1490.2611 - val_loss: 1701.6669 - val_mse: 1701.6669\n",
            "Epoch 10/15\n",
            "438/438 - 4s - loss: 1481.4490 - mse: 1481.4490 - val_loss: 1664.8447 - val_mse: 1664.8447\n",
            "Epoch 11/15\n",
            "438/438 - 4s - loss: 1473.6097 - mse: 1473.6097 - val_loss: 1662.6307 - val_mse: 1662.6307\n",
            "Epoch 12/15\n",
            "438/438 - 4s - loss: 1463.9440 - mse: 1463.9440 - val_loss: 1666.0996 - val_mse: 1666.0996\n",
            "Epoch 13/15\n",
            "438/438 - 4s - loss: 1465.5818 - mse: 1465.5818 - val_loss: 1643.4600 - val_mse: 1643.4600\n",
            "Epoch 14/15\n",
            "438/438 - 4s - loss: 1450.7035 - mse: 1450.7035 - val_loss: 1712.1953 - val_mse: 1712.1953\n",
            "Epoch 15/15\n",
            "438/438 - 4s - loss: 1459.3042 - mse: 1459.3042 - val_loss: 1644.2532 - val_mse: 1644.2532\n",
            "Fold Score:  1643.4599609375\n",
            "Training fold: 9\n",
            "Epoch 1/15\n",
            "438/438 - 4s - loss: 2046.9418 - mse: 2046.9418 - val_loss: 1583.9727 - val_mse: 1583.9727\n",
            "Epoch 2/15\n",
            "438/438 - 4s - loss: 1596.7499 - mse: 1596.7499 - val_loss: 1543.2974 - val_mse: 1543.2974\n",
            "Epoch 3/15\n",
            "438/438 - 4s - loss: 1567.6736 - mse: 1567.6736 - val_loss: 1499.1426 - val_mse: 1499.1426\n",
            "Epoch 4/15\n",
            "438/438 - 6s - loss: 1547.6359 - mse: 1547.6359 - val_loss: 1482.9419 - val_mse: 1482.9419\n",
            "Epoch 5/15\n",
            "438/438 - 5s - loss: 1528.8783 - mse: 1528.8783 - val_loss: 1474.6384 - val_mse: 1474.6384\n",
            "Epoch 6/15\n",
            "438/438 - 4s - loss: 1521.6145 - mse: 1521.6145 - val_loss: 1477.8029 - val_mse: 1477.8029\n",
            "Epoch 7/15\n",
            "438/438 - 4s - loss: 1513.1530 - mse: 1513.1530 - val_loss: 1512.6903 - val_mse: 1512.6903\n",
            "Epoch 8/15\n",
            "438/438 - 4s - loss: 1503.5435 - mse: 1503.5435 - val_loss: 1486.6555 - val_mse: 1486.6555\n",
            "Epoch 9/15\n",
            "438/438 - 4s - loss: 1501.1235 - mse: 1501.1235 - val_loss: 1476.3323 - val_mse: 1476.3323\n",
            "Epoch 10/15\n",
            "438/438 - 4s - loss: 1496.2664 - mse: 1496.2664 - val_loss: 1466.9913 - val_mse: 1466.9913\n",
            "Epoch 11/15\n",
            "438/438 - 4s - loss: 1490.5022 - mse: 1490.5022 - val_loss: 1445.8641 - val_mse: 1445.8641\n",
            "Epoch 12/15\n",
            "438/438 - 4s - loss: 1478.2877 - mse: 1478.2877 - val_loss: 1446.6681 - val_mse: 1446.6681\n",
            "Epoch 13/15\n",
            "438/438 - 4s - loss: 1482.1115 - mse: 1482.1115 - val_loss: 1476.8824 - val_mse: 1476.8824\n",
            "Epoch 14/15\n",
            "438/438 - 4s - loss: 1466.9963 - mse: 1466.9963 - val_loss: 1449.0708 - val_mse: 1449.0708\n",
            "Epoch 15/15\n",
            "438/438 - 4s - loss: 1454.9698 - mse: 1454.9698 - val_loss: 1535.2943 - val_mse: 1535.2943\n",
            "Fold Score:  1445.8641357421875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agV6B0sxngel",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0beff182-5780-4f17-a2af-adb1dbc61deb"
      },
      "source": [
        "print(mean(cnnScores))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1471.9548950195312\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOPZP5Qq5JHv",
        "colab_type": "text"
      },
      "source": [
        "# LSTM NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0xiNtqg5IW6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d65d1ff4-874a-480d-c445-38aeffbc25b2"
      },
      "source": [
        "def createLSTM(inputSize):\n",
        "    model = keras.Sequential()\n",
        "    model.add(keras.layers.LSTM(32, activation='relu', return_sequences=True, input_shape=(121,6)))\n",
        "    model.add(keras.layers.Dense(64, activation='sigmoid'))\n",
        "    model.add(keras.layers.Dense(1, activation='relu'))\n",
        "    \n",
        "    model.compile(loss='mse', # keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "        optimizer='adam',\n",
        "        metrics=['mse'])\n",
        "    return model\n",
        "\n",
        "lstmScores = testAlgorithm(createLSTM)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training fold: 0\n",
            "Epoch 1/15\n",
            "438/438 - 20s - loss: 4081.3333 - mse: 4081.3333 - val_loss: 2807.4050 - val_mse: 2807.4050\n",
            "Epoch 2/15\n",
            "438/438 - 21s - loss: 2437.9546 - mse: 2437.9546 - val_loss: 1779.8870 - val_mse: 1779.8870\n",
            "Epoch 3/15\n",
            "438/438 - 21s - loss: 1894.7593 - mse: 1894.7593 - val_loss: 1621.4983 - val_mse: 1621.4983\n",
            "Epoch 4/15\n",
            "438/438 - 21s - loss: 1827.3748 - mse: 1827.3748 - val_loss: 1607.9473 - val_mse: 1607.9473\n",
            "Epoch 5/15\n",
            "438/438 - 21s - loss: 1816.4807 - mse: 1816.4807 - val_loss: 1599.4346 - val_mse: 1599.4346\n",
            "Epoch 6/15\n",
            "438/438 - 21s - loss: 1808.3716 - mse: 1808.3716 - val_loss: 1598.8765 - val_mse: 1598.8765\n",
            "Epoch 7/15\n",
            "438/438 - 21s - loss: 1805.0896 - mse: 1805.0896 - val_loss: 1589.9752 - val_mse: 1589.9752\n",
            "Epoch 8/15\n",
            "438/438 - 21s - loss: 1798.4478 - mse: 1798.4478 - val_loss: 1584.4728 - val_mse: 1584.4728\n",
            "Epoch 9/15\n",
            "438/438 - 21s - loss: 1793.1252 - mse: 1793.1252 - val_loss: 1579.9156 - val_mse: 1579.9156\n",
            "Epoch 10/15\n",
            "438/438 - 21s - loss: 1786.9968 - mse: 1786.9968 - val_loss: 1572.9227 - val_mse: 1572.9227\n",
            "Epoch 11/15\n",
            "438/438 - 21s - loss: 1781.0204 - mse: 1781.0204 - val_loss: 1570.1147 - val_mse: 1570.1147\n",
            "Epoch 12/15\n",
            "438/438 - 22s - loss: 1777.0352 - mse: 1777.0352 - val_loss: 1566.5264 - val_mse: 1566.5264\n",
            "Epoch 13/15\n",
            "438/438 - 22s - loss: 1773.9550 - mse: 1773.9550 - val_loss: 1561.7799 - val_mse: 1561.7799\n",
            "Epoch 14/15\n",
            "438/438 - 22s - loss: 1775.1316 - mse: 1775.1316 - val_loss: 1567.4174 - val_mse: 1567.4174\n",
            "Epoch 15/15\n",
            "438/438 - 21s - loss: 1786.2950 - mse: 1786.2950 - val_loss: 1578.4762 - val_mse: 1578.4762\n",
            "Fold Score:  1561.7799072265625\n",
            "Training fold: 1\n",
            "Epoch 1/15\n",
            "438/438 - 20s - loss: 4032.2407 - mse: 4032.2407 - val_loss: 3159.8796 - val_mse: 3159.8796\n",
            "Epoch 2/15\n",
            "438/438 - 22s - loss: 2407.5930 - mse: 2407.5930 - val_loss: 2062.5889 - val_mse: 2062.5889\n",
            "Epoch 3/15\n",
            "438/438 - 21s - loss: 1863.4507 - mse: 1863.4507 - val_loss: 1853.1124 - val_mse: 1853.1124\n",
            "Epoch 4/15\n",
            "438/438 - 21s - loss: 1791.9468 - mse: 1791.9468 - val_loss: 1829.8562 - val_mse: 1829.8562\n",
            "Epoch 5/15\n",
            "438/438 - 21s - loss: 1785.4065 - mse: 1785.4065 - val_loss: 1826.2098 - val_mse: 1826.2098\n",
            "Epoch 6/15\n",
            "438/438 - 21s - loss: 1780.8727 - mse: 1780.8727 - val_loss: 1820.3154 - val_mse: 1820.3154\n",
            "Epoch 7/15\n",
            "438/438 - 21s - loss: 1775.1575 - mse: 1775.1575 - val_loss: 1812.6974 - val_mse: 1812.6974\n",
            "Epoch 8/15\n",
            "438/438 - 22s - loss: 1768.6503 - mse: 1768.6503 - val_loss: 1804.8385 - val_mse: 1804.8385\n",
            "Epoch 9/15\n",
            "438/438 - 21s - loss: 1760.9038 - mse: 1760.9038 - val_loss: 1795.7550 - val_mse: 1795.7550\n",
            "Epoch 10/15\n",
            "438/438 - 21s - loss: 1753.8113 - mse: 1753.8113 - val_loss: 1788.9326 - val_mse: 1788.9326\n",
            "Epoch 11/15\n",
            "438/438 - 21s - loss: 1746.5946 - mse: 1746.5946 - val_loss: 1778.4447 - val_mse: 1778.4447\n",
            "Epoch 12/15\n",
            "438/438 - 24s - loss: 1739.0264 - mse: 1739.0264 - val_loss: 1770.4369 - val_mse: 1770.4369\n",
            "Epoch 13/15\n",
            "438/438 - 22s - loss: 1731.4851 - mse: 1731.4851 - val_loss: 1759.8628 - val_mse: 1759.8628\n",
            "Epoch 14/15\n",
            "438/438 - 21s - loss: 1752.9305 - mse: 1752.9305 - val_loss: 1805.2798 - val_mse: 1805.2798\n",
            "Epoch 15/15\n",
            "438/438 - 21s - loss: 1762.6650 - mse: 1762.6650 - val_loss: 1803.5057 - val_mse: 1803.5057\n",
            "Fold Score:  1759.86279296875\n",
            "Training fold: 2\n",
            "Epoch 1/15\n",
            "438/438 - 20s - loss: 4029.0388 - mse: 4029.0388 - val_loss: 3092.4148 - val_mse: 3092.4148\n",
            "Epoch 2/15\n",
            "438/438 - 21s - loss: 2347.6362 - mse: 2347.6362 - val_loss: 2068.5391 - val_mse: 2068.5391\n",
            "Epoch 3/15\n",
            "438/438 - 21s - loss: 1853.9341 - mse: 1853.9341 - val_loss: 1890.2046 - val_mse: 1890.2046\n",
            "Epoch 4/15\n",
            "438/438 - 21s - loss: 1794.2618 - mse: 1794.2618 - val_loss: 1872.5044 - val_mse: 1872.5044\n",
            "Epoch 5/15\n",
            "438/438 - 21s - loss: 1788.8452 - mse: 1788.8452 - val_loss: 1868.6722 - val_mse: 1868.6722\n",
            "Epoch 6/15\n",
            "438/438 - 21s - loss: 1786.3903 - mse: 1786.3903 - val_loss: 1866.9440 - val_mse: 1866.9440\n",
            "Epoch 7/15\n",
            "438/438 - 21s - loss: 1784.2383 - mse: 1784.2383 - val_loss: 1863.6930 - val_mse: 1863.6930\n",
            "Epoch 8/15\n",
            "438/438 - 21s - loss: 1780.0990 - mse: 1780.0990 - val_loss: 1858.0778 - val_mse: 1858.0778\n",
            "Epoch 9/15\n",
            "438/438 - 21s - loss: 1771.8582 - mse: 1771.8582 - val_loss: 1850.4868 - val_mse: 1850.4868\n",
            "Epoch 10/15\n",
            "438/438 - 22s - loss: 1761.0137 - mse: 1761.0137 - val_loss: 1838.7833 - val_mse: 1838.7833\n",
            "Epoch 11/15\n",
            "438/438 - 22s - loss: 1755.1804 - mse: 1755.1804 - val_loss: 1835.8956 - val_mse: 1835.8956\n",
            "Epoch 12/15\n",
            "438/438 - 21s - loss: 1754.8059 - mse: 1754.8059 - val_loss: 1833.4333 - val_mse: 1833.4333\n",
            "Epoch 13/15\n",
            "438/438 - 21s - loss: 1748.4058 - mse: 1748.4058 - val_loss: 1815.4081 - val_mse: 1815.4081\n",
            "Epoch 14/15\n",
            "438/438 - 22s - loss: 1736.0298 - mse: 1736.0298 - val_loss: 1808.1851 - val_mse: 1808.1851\n",
            "Epoch 15/15\n",
            "438/438 - 21s - loss: 1729.0315 - mse: 1729.0315 - val_loss: 1803.8259 - val_mse: 1803.8259\n",
            "Fold Score:  1803.825927734375\n",
            "Training fold: 3\n",
            "Epoch 1/15\n",
            "438/438 - 20s - loss: 4016.6792 - mse: 4016.6792 - val_loss: 2816.3079 - val_mse: 2816.3079\n",
            "Epoch 2/15\n",
            "438/438 - 21s - loss: 2393.5916 - mse: 2393.5916 - val_loss: 1804.9003 - val_mse: 1804.9003\n",
            "Epoch 3/15\n",
            "438/438 - 21s - loss: 1883.3450 - mse: 1883.3450 - val_loss: 1643.2172 - val_mse: 1643.2172\n",
            "Epoch 4/15\n",
            "438/438 - 22s - loss: 1818.1626 - mse: 1818.1626 - val_loss: 1629.7668 - val_mse: 1629.7668\n",
            "Epoch 5/15\n",
            "438/438 - 21s - loss: 1810.3702 - mse: 1810.3702 - val_loss: 1625.7024 - val_mse: 1625.7024\n",
            "Epoch 6/15\n",
            "438/438 - 22s - loss: 1805.5723 - mse: 1805.5723 - val_loss: 1620.5020 - val_mse: 1620.5020\n",
            "Epoch 7/15\n",
            "438/438 - 22s - loss: 1799.8623 - mse: 1799.8623 - val_loss: 1613.2643 - val_mse: 1613.2643\n",
            "Epoch 8/15\n",
            "438/438 - 21s - loss: 1789.7889 - mse: 1789.7889 - val_loss: 1602.9403 - val_mse: 1602.9403\n",
            "Epoch 9/15\n",
            "438/438 - 21s - loss: 1779.3800 - mse: 1779.3800 - val_loss: 1593.2909 - val_mse: 1593.2909\n",
            "Epoch 10/15\n",
            "438/438 - 25s - loss: 1770.0769 - mse: 1770.0769 - val_loss: 1586.0096 - val_mse: 1586.0096\n",
            "Epoch 11/15\n",
            "438/438 - 23s - loss: 1758.6156 - mse: 1758.6156 - val_loss: 1575.0582 - val_mse: 1575.0582\n",
            "Epoch 12/15\n",
            "438/438 - 22s - loss: 1749.5381 - mse: 1749.5381 - val_loss: 1567.3370 - val_mse: 1567.3370\n",
            "Epoch 13/15\n",
            "438/438 - 21s - loss: 1743.6517 - mse: 1743.6517 - val_loss: 1563.0570 - val_mse: 1563.0570\n",
            "Epoch 14/15\n",
            "438/438 - 21s - loss: 1736.3938 - mse: 1736.3938 - val_loss: 1556.3119 - val_mse: 1556.3119\n",
            "Epoch 15/15\n",
            "438/438 - 22s - loss: 1730.6847 - mse: 1730.6847 - val_loss: 1556.2656 - val_mse: 1556.2656\n",
            "Fold Score:  1556.265625\n",
            "Training fold: 4\n",
            "Epoch 1/15\n",
            "438/438 - 20s - loss: 4076.4812 - mse: 4076.4812 - val_loss: 3037.3665 - val_mse: 3037.3665\n",
            "Epoch 2/15\n",
            "438/438 - 20s - loss: 2379.5059 - mse: 2379.5059 - val_loss: 1967.4590 - val_mse: 1967.4590\n",
            "Epoch 3/15\n",
            "438/438 - 21s - loss: 1864.7336 - mse: 1864.7336 - val_loss: 1801.5526 - val_mse: 1801.5526\n",
            "Epoch 4/15\n",
            "438/438 - 21s - loss: 1805.3837 - mse: 1805.3837 - val_loss: 1787.3840 - val_mse: 1787.3840\n",
            "Epoch 5/15\n",
            "438/438 - 22s - loss: 1797.4362 - mse: 1797.4362 - val_loss: 1779.5167 - val_mse: 1779.5167\n",
            "Epoch 6/15\n",
            "438/438 - 21s - loss: 1790.2434 - mse: 1790.2434 - val_loss: 1771.3011 - val_mse: 1771.3011\n",
            "Epoch 7/15\n",
            "438/438 - 21s - loss: 1782.1078 - mse: 1782.1078 - val_loss: 1762.3239 - val_mse: 1762.3239\n",
            "Epoch 8/15\n",
            "438/438 - 22s - loss: 1774.2966 - mse: 1774.2966 - val_loss: 1754.6290 - val_mse: 1754.6290\n",
            "Epoch 9/15\n",
            "438/438 - 22s - loss: 1767.5023 - mse: 1767.5023 - val_loss: 1747.6426 - val_mse: 1747.6426\n",
            "Epoch 10/15\n",
            "438/438 - 23s - loss: 1761.2000 - mse: 1761.2000 - val_loss: 1742.8835 - val_mse: 1742.8835\n",
            "Epoch 11/15\n",
            "438/438 - 22s - loss: 1756.6577 - mse: 1756.6577 - val_loss: 1738.2438 - val_mse: 1738.2438\n",
            "Epoch 12/15\n",
            "438/438 - 21s - loss: 1752.3124 - mse: 1752.3124 - val_loss: 1734.9867 - val_mse: 1734.9867\n",
            "Epoch 13/15\n",
            "438/438 - 22s - loss: 1748.7954 - mse: 1748.7954 - val_loss: 1730.7241 - val_mse: 1730.7241\n",
            "Epoch 14/15\n",
            "438/438 - 21s - loss: 1745.6460 - mse: 1745.6460 - val_loss: 1727.7793 - val_mse: 1727.7793\n",
            "Epoch 15/15\n",
            "438/438 - 21s - loss: 1742.7981 - mse: 1742.7981 - val_loss: 1725.5796 - val_mse: 1725.5796\n",
            "Fold Score:  1725.57958984375\n",
            "Training fold: 5\n",
            "Epoch 1/15\n",
            "438/438 - 20s - loss: 3914.6560 - mse: 3914.6560 - val_loss: 3160.1946 - val_mse: 3160.1946\n",
            "Epoch 2/15\n",
            "438/438 - 22s - loss: 2294.0605 - mse: 2294.0605 - val_loss: 2197.4709 - val_mse: 2197.4709\n",
            "Epoch 3/15\n",
            "438/438 - 21s - loss: 1840.7017 - mse: 1840.7017 - val_loss: 2030.3812 - val_mse: 2030.3812\n",
            "Epoch 4/15\n",
            "438/438 - 21s - loss: 1782.9865 - mse: 1782.9865 - val_loss: 2011.7399 - val_mse: 2011.7399\n",
            "Epoch 5/15\n",
            "438/438 - 21s - loss: 1777.0065 - mse: 1777.0065 - val_loss: 2007.4252 - val_mse: 2007.4252\n",
            "Epoch 6/15\n",
            "438/438 - 21s - loss: 1773.6210 - mse: 1773.6210 - val_loss: 2003.5452 - val_mse: 2003.5452\n",
            "Epoch 7/15\n",
            "438/438 - 21s - loss: 1770.4591 - mse: 1770.4591 - val_loss: 1999.5747 - val_mse: 1999.5747\n",
            "Epoch 8/15\n",
            "438/438 - 24s - loss: 1767.3279 - mse: 1767.3279 - val_loss: 1996.2169 - val_mse: 1996.2169\n",
            "Epoch 9/15\n",
            "438/438 - 23s - loss: 1764.8595 - mse: 1764.8595 - val_loss: 1993.5616 - val_mse: 1993.5616\n",
            "Epoch 10/15\n",
            "438/438 - 22s - loss: 1761.2054 - mse: 1761.2054 - val_loss: 1988.5806 - val_mse: 1988.5806\n",
            "Epoch 11/15\n",
            "438/438 - 21s - loss: 1757.7806 - mse: 1757.7806 - val_loss: 1984.5116 - val_mse: 1984.5116\n",
            "Epoch 12/15\n",
            "438/438 - 21s - loss: 1755.0240 - mse: 1755.0240 - val_loss: 1984.0411 - val_mse: 1984.0411\n",
            "Epoch 13/15\n",
            "438/438 - 22s - loss: 1753.0785 - mse: 1753.0785 - val_loss: 1980.0404 - val_mse: 1980.0404\n",
            "Epoch 14/15\n",
            "438/438 - 21s - loss: 1756.3552 - mse: 1756.3552 - val_loss: 1972.8640 - val_mse: 1972.8640\n",
            "Epoch 15/15\n",
            "438/438 - 21s - loss: 1746.7042 - mse: 1746.7042 - val_loss: 1971.0428 - val_mse: 1971.0428\n",
            "Fold Score:  1971.0428466796875\n",
            "Training fold: 6\n",
            "Epoch 1/15\n",
            "438/438 - 20s - loss: 3975.9131 - mse: 3975.9131 - val_loss: 2935.6670 - val_mse: 2935.6670\n",
            "Epoch 2/15\n",
            "438/438 - 21s - loss: 2338.1494 - mse: 2338.1494 - val_loss: 1987.0105 - val_mse: 1987.0105\n",
            "Epoch 3/15\n",
            "438/438 - 21s - loss: 1852.0895 - mse: 1852.0895 - val_loss: 1844.0177 - val_mse: 1844.0177\n",
            "Epoch 4/15\n",
            "438/438 - 21s - loss: 1787.8580 - mse: 1787.8580 - val_loss: 1833.1957 - val_mse: 1833.1957\n",
            "Epoch 5/15\n",
            "438/438 - 21s - loss: 1780.4672 - mse: 1780.4672 - val_loss: 1829.2426 - val_mse: 1829.2426\n",
            "Epoch 6/15\n",
            "438/438 - 22s - loss: 1775.2998 - mse: 1775.2998 - val_loss: 1823.7433 - val_mse: 1823.7433\n",
            "Epoch 7/15\n",
            "438/438 - 21s - loss: 1768.6407 - mse: 1768.6407 - val_loss: 1816.6184 - val_mse: 1816.6184\n",
            "Epoch 8/15\n",
            "438/438 - 21s - loss: 1760.1007 - mse: 1760.1007 - val_loss: 1810.2878 - val_mse: 1810.2878\n",
            "Epoch 9/15\n",
            "438/438 - 23s - loss: 1752.5614 - mse: 1752.5614 - val_loss: 1805.5065 - val_mse: 1805.5065\n",
            "Epoch 10/15\n",
            "438/438 - 22s - loss: 1746.6139 - mse: 1746.6139 - val_loss: 1800.2764 - val_mse: 1800.2764\n",
            "Epoch 11/15\n",
            "438/438 - 21s - loss: 1739.1606 - mse: 1739.1606 - val_loss: 1792.7875 - val_mse: 1792.7875\n",
            "Epoch 12/15\n",
            "438/438 - 22s - loss: 1753.7825 - mse: 1753.7825 - val_loss: 1816.6897 - val_mse: 1816.6897\n",
            "Epoch 13/15\n",
            "438/438 - 22s - loss: 1749.5239 - mse: 1749.5239 - val_loss: 1809.1279 - val_mse: 1809.1279\n",
            "Epoch 14/15\n",
            "438/438 - 21s - loss: 1751.0687 - mse: 1751.0687 - val_loss: 1802.7551 - val_mse: 1802.7551\n",
            "Epoch 15/15\n",
            "438/438 - 21s - loss: 1743.6562 - mse: 1743.6562 - val_loss: 1794.1224 - val_mse: 1794.1224\n",
            "Fold Score:  1792.7874755859375\n",
            "Training fold: 7\n",
            "Epoch 1/15\n",
            "438/438 - 20s - loss: 3990.7124 - mse: 3990.7124 - val_loss: 2736.3914 - val_mse: 2736.3914\n",
            "Epoch 2/15\n",
            "438/438 - 22s - loss: 2354.2917 - mse: 2354.2917 - val_loss: 1806.0482 - val_mse: 1806.0482\n",
            "Epoch 3/15\n",
            "438/438 - 22s - loss: 1872.5062 - mse: 1872.5062 - val_loss: 1666.0138 - val_mse: 1666.0138\n",
            "Epoch 4/15\n",
            "438/438 - 21s - loss: 1811.3179 - mse: 1811.3179 - val_loss: 1656.0848 - val_mse: 1656.0848\n",
            "Epoch 5/15\n",
            "438/438 - 21s - loss: 1804.7402 - mse: 1804.7402 - val_loss: 1653.9991 - val_mse: 1653.9991\n",
            "Epoch 6/15\n",
            "438/438 - 22s - loss: 1800.3645 - mse: 1800.3645 - val_loss: 1648.8336 - val_mse: 1648.8336\n",
            "Epoch 7/15\n",
            "438/438 - 25s - loss: 1798.0865 - mse: 1798.0865 - val_loss: 1651.1544 - val_mse: 1651.1544\n",
            "Epoch 8/15\n",
            "438/438 - 23s - loss: 1793.9266 - mse: 1793.9266 - val_loss: 1644.9369 - val_mse: 1644.9369\n",
            "Epoch 9/15\n",
            "438/438 - 21s - loss: 1789.9374 - mse: 1789.9374 - val_loss: 1641.7046 - val_mse: 1641.7046\n",
            "Epoch 10/15\n",
            "438/438 - 22s - loss: 1785.3367 - mse: 1785.3367 - val_loss: 1637.8450 - val_mse: 1637.8450\n",
            "Epoch 11/15\n",
            "438/438 - 21s - loss: 1780.9897 - mse: 1780.9897 - val_loss: 1635.0204 - val_mse: 1635.0204\n",
            "Epoch 12/15\n",
            "438/438 - 22s - loss: 1777.6379 - mse: 1777.6379 - val_loss: 1631.8494 - val_mse: 1631.8494\n",
            "Epoch 13/15\n",
            "438/438 - 22s - loss: 1774.7156 - mse: 1774.7156 - val_loss: 1629.6011 - val_mse: 1629.6011\n",
            "Epoch 14/15\n",
            "438/438 - 22s - loss: 1772.3281 - mse: 1772.3281 - val_loss: 1627.7454 - val_mse: 1627.7454\n",
            "Epoch 15/15\n",
            "438/438 - 22s - loss: 1769.9144 - mse: 1769.9144 - val_loss: 1626.0958 - val_mse: 1626.0958\n",
            "Fold Score:  1626.0958251953125\n",
            "Training fold: 8\n",
            "Epoch 1/15\n",
            "438/438 - 20s - loss: 3966.5715 - mse: 3966.5715 - val_loss: 3078.3684 - val_mse: 3078.3684\n",
            "Epoch 2/15\n",
            "438/438 - 22s - loss: 2357.5435 - mse: 2357.5435 - val_loss: 2118.8069 - val_mse: 2118.8069\n",
            "Epoch 3/15\n",
            "438/438 - 22s - loss: 1855.3160 - mse: 1855.3160 - val_loss: 1941.8751 - val_mse: 1941.8751\n",
            "Epoch 4/15\n",
            "438/438 - 21s - loss: 1783.4430 - mse: 1783.4430 - val_loss: 1922.7830 - val_mse: 1922.7830\n",
            "Epoch 5/15\n",
            "438/438 - 22s - loss: 1772.5466 - mse: 1772.5466 - val_loss: 1916.6233 - val_mse: 1916.6233\n",
            "Epoch 6/15\n",
            "438/438 - 22s - loss: 1766.4135 - mse: 1766.4135 - val_loss: 1911.6180 - val_mse: 1911.6180\n",
            "Epoch 7/15\n",
            "438/438 - 22s - loss: 1760.6002 - mse: 1760.6002 - val_loss: 1907.7288 - val_mse: 1907.7288\n",
            "Epoch 8/15\n",
            "438/438 - 22s - loss: 1756.7937 - mse: 1756.7937 - val_loss: 1904.5875 - val_mse: 1904.5875\n",
            "Epoch 9/15\n",
            "438/438 - 22s - loss: 1753.4186 - mse: 1753.4186 - val_loss: 1902.6461 - val_mse: 1902.6461\n",
            "Epoch 10/15\n",
            "438/438 - 22s - loss: 1751.1115 - mse: 1751.1115 - val_loss: 1900.6301 - val_mse: 1900.6301\n",
            "Epoch 11/15\n",
            "438/438 - 22s - loss: 1748.8077 - mse: 1748.8077 - val_loss: 1898.8270 - val_mse: 1898.8270\n",
            "Epoch 12/15\n",
            "438/438 - 22s - loss: 1746.1748 - mse: 1746.1748 - val_loss: 1896.5452 - val_mse: 1896.5452\n",
            "Epoch 13/15\n",
            "438/438 - 22s - loss: 1743.2531 - mse: 1743.2531 - val_loss: 1894.8143 - val_mse: 1894.8143\n",
            "Epoch 14/15\n",
            "438/438 - 22s - loss: 1740.9369 - mse: 1740.9369 - val_loss: 1892.4039 - val_mse: 1892.4039\n",
            "Epoch 15/15\n",
            "438/438 - 22s - loss: 1738.4293 - mse: 1738.4293 - val_loss: 1890.3824 - val_mse: 1890.3824\n",
            "Fold Score:  1890.3824462890625\n",
            "Training fold: 9\n",
            "Epoch 1/15\n",
            "438/438 - 20s - loss: 3832.9771 - mse: 3832.9771 - val_loss: 2945.7163 - val_mse: 2945.7163\n",
            "Epoch 2/15\n",
            "438/438 - 20s - loss: 2442.7910 - mse: 2442.7910 - val_loss: 2032.4105 - val_mse: 2032.4105\n",
            "Epoch 3/15\n",
            "438/438 - 20s - loss: 1903.7555 - mse: 1903.7555 - val_loss: 1818.8611 - val_mse: 1818.8611\n",
            "Epoch 4/15\n",
            "438/438 - 22s - loss: 1803.5006 - mse: 1803.5006 - val_loss: 1796.9938 - val_mse: 1796.9938\n",
            "Epoch 5/15\n",
            "438/438 - 22s - loss: 1792.6224 - mse: 1792.6224 - val_loss: 1795.5231 - val_mse: 1795.5231\n",
            "Epoch 6/15\n",
            "438/438 - 20s - loss: 1796.7501 - mse: 1796.7501 - val_loss: 1789.8933 - val_mse: 1789.8933\n",
            "Epoch 7/15\n",
            "438/438 - 20s - loss: 1776.1815 - mse: 1776.1815 - val_loss: 1771.6995 - val_mse: 1771.6995\n",
            "Epoch 8/15\n",
            "438/438 - 20s - loss: 1761.3297 - mse: 1761.3297 - val_loss: 1758.3813 - val_mse: 1758.3813\n",
            "Epoch 9/15\n",
            "438/438 - 20s - loss: 1751.6614 - mse: 1751.6614 - val_loss: 1750.5439 - val_mse: 1750.5439\n",
            "Epoch 10/15\n",
            "438/438 - 20s - loss: 1743.0864 - mse: 1743.0864 - val_loss: 1741.7147 - val_mse: 1741.7147\n",
            "Epoch 11/15\n",
            "438/438 - 20s - loss: 1736.3447 - mse: 1736.3447 - val_loss: 1735.0858 - val_mse: 1735.0858\n",
            "Epoch 12/15\n",
            "438/438 - 20s - loss: 1731.2568 - mse: 1731.2568 - val_loss: 1730.4576 - val_mse: 1730.4576\n",
            "Epoch 13/15\n",
            "438/438 - 20s - loss: 1726.5757 - mse: 1726.5757 - val_loss: 1724.9506 - val_mse: 1724.9506\n",
            "Epoch 14/15\n",
            "438/438 - 20s - loss: 1722.0995 - mse: 1722.0995 - val_loss: 1720.2991 - val_mse: 1720.2991\n",
            "Epoch 15/15\n",
            "438/438 - 20s - loss: 1717.8555 - mse: 1717.8555 - val_loss: 1715.9525 - val_mse: 1715.9525\n",
            "Fold Score:  1715.9525146484375\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElAHb7aYNLCK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "52932d9a-8899-403d-fc67-51b81fc04677"
      },
      "source": [
        "print(mean(lstmScores))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1740.3574951171875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9X-UzEETL-dP",
        "colab_type": "text"
      },
      "source": [
        "# Comparison"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSd5aNgmMAwu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy.stats import wilcoxon"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lWmEmzXvzs1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def benefitOfTheDoubt(scores):\n",
        "      legitScores = []\n",
        "      for score in scores:\n",
        "          if str(score) != 'nan':\n",
        "              legitScores.append(score)\n",
        "      replacement = mean(legitScores)\n",
        "      newScores = []\n",
        "      for score in scores:\n",
        "          if str(score) == 'nan':\n",
        "              newScores.append(replacement)\n",
        "          else:\n",
        "              newScores.append(score)\n",
        "      return newScores\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqVpMzT1MPx4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f1946ffa-deb0-42ce-e3c2-13a71c2ed124"
      },
      "source": [
        "def calculateTStatistic(data1, data2, alpha = 0.1, description = \"\"):\n",
        "    out = []   \n",
        "    stat, p = wilcoxon(data1, data2)    \n",
        "    print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
        "    out.append(\"\\n\" + description + \"\\tStatistics=\" + str(round(stat,8)) + \"\\tP value= \" + str(round(p,8)))\n",
        "    if p > alpha:\n",
        "        out.append(\"\\n\" + description + '\\tSame distribution (fail to reject H0) at ' + str(alpha))\n",
        "    else:\n",
        "        out.append(\"\\n\" + description + '\\tDifferent distribution (reject H0) at ' + str(alpha))\n",
        "    return out\n",
        "\n",
        "print(calculateTStatistic(\n",
        "    benefitOfTheDoubt(cnnScores), \n",
        "    benefitOfTheDoubt(lstmScores))\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Statistics=0.000, p=0.005\n",
            "['\\n\\tStatistics=0.0\\tP value= 0.00506203', '\\n\\tDifferent distribution (reject H0) at 0.1']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDBo-_e1Dsw4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "a0782391-568e-4e4c-9fdb-1f7c98ca5f5c"
      },
      "source": [
        "def printStatistics(data, description = \"\"):\n",
        "    print(\"Mean of \", description, \" is: \", str(mean(data)))\n",
        "    print(\"Std of \", description, \" is: \", str(std(data)))\n",
        "\n",
        "printStatistics(benefitOfTheDoubt(cnnScores), \"CNN\")\n",
        "printStatistics(benefitOfTheDoubt(lstmScores), \"LSTM\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean of  CNN  is:  1471.9548950195312\n",
            "Std of  CNN  is:  123.77456204718196\n",
            "Mean of  LSTM  is:  1740.3574951171875\n",
            "Std of  LSTM  is:  127.48737550993646\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}